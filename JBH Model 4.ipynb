{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from scipy import stats\n",
    "stats.chisqrob = lambda chisq, df: stats.chi2.sf(chisq,df)\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('500_B.csv')     #import data \n",
    "DNB = raw_data.copy()\n",
    "print(list(DNB.columns))                #print column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 999)      # display setting \n",
    "DNB.head()                                     # dataset overview "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_col(col):                    # formatting the column names (headers)\n",
    "    col = col.strip()\n",
    "    col = col.replace(\" \",\"_\")\n",
    "    col = col.lower()\n",
    "    return col\n",
    "\n",
    "new_columns = []\n",
    "for c in DNB.columns:\n",
    "    clean_c = format_col(c)\n",
    "    new_columns.append(clean_c)\n",
    "    \n",
    "DNB.columns = new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DNB.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNB.loc[:,'*1-15':'uccfilng'] = DNB.loc[:,'*1-15':'\n",
    "                                        uccfilng'].astype(float)  #converting all data values to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNB.head(5)   # dataset overview (checking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers(dataslice, rows=20):           # function to replace outliers with 'None' within a range of columns\n",
    "    \n",
    "    def outlier(list):\n",
    "        Q1 = np.percentile(list, 25)\n",
    "        Q2 = np.percentile(list, 50)\n",
    "        Q3 = np.percentile(list, 75)\n",
    "        IQR = Q3 - Q1\n",
    "        L_outlier = Q1 - 1.5*IQR\n",
    "        H_outlier = Q3 + 1.5*IQR\n",
    "\n",
    "        outlier_list = []\n",
    "        for number in list:\n",
    "            if number <= L_outlier or number >= H_outlier:\n",
    "                outlier_list.append(number)\n",
    "        return outlier_list\n",
    "\n",
    "    \n",
    "    def clear_outliers(list):\n",
    "        outliers = outlier(list)\n",
    "        new_list =[]\n",
    "        for number in list:\n",
    "            if number in outliers:\n",
    "                new_list.append(None)\n",
    "            else:\n",
    "                new_list.append(number)\n",
    "        return new_list  \n",
    "\n",
    "    col = dataslice          #DNB.loc[:,'bd_ind':'uccfilng']\n",
    "    clmn = list(col)\n",
    "    for a in clmn:\n",
    "        col[a] = clear_outliers(col[a])\n",
    "        DNB[a] = col[a]\n",
    "    \n",
    "    pd.set_option('display.max_columns', 999)\n",
    "    \n",
    "    return DNB.head(rows)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_outliers(DNB.loc[:,'bd_ind':'uccfilng'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_row = DNB.shape[0]  # gives number of row count\n",
    "count_col = DNB.shape[1]\n",
    "print(count_row,count_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNB.drop([\"bd_ind\",\"bnkrpt\",\"ob_ind\",\"stmt_ind\"], axis=1, inplace=True)    # drop 'None' values\n",
    "DNB.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_row = DNB.shape[0]  # gives number of row count\n",
    "count_col = DNB.shape[1]\n",
    "print(count_row,count_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export csv.file\n",
    "DNB.to_csv(r'C:\\Users\\Tom\\Desktop\\UF Life\\ISOM\\JB Hunt\\JBHunt - Fall 2019\\JBHunt - Fall 2019\\WORK\\CSV\\export_dataframe_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = DNB['w_pastdue_2']     # assign y-variables\n",
    "cols = ['cpct', 'crating_composite', 'd_neg', 'fpct', 'fscore', 'fspoints', 'hicdtmax', 'liens', 'npayexpp', 'orating_composite', 'payexp_n', 'paynorm', 'avg_pydx_12', 'avg_pydx_24', 'sub_ind', 'suits', 'totdoll', 'uccfilng']\n",
    "x = DNB[cols]                   # assign x-variables\n",
    "x = sm.add_constant(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = sm.OLS(y, x).fit()              # run linear regression model\n",
    "#predictions = model.predict(x) \n",
    "print_model = model.summary2()\n",
    "print(print_model)                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.pvalues)       #params, bse (Std.Err.), tvalues, pvalues, predict(), rsquared_adj, rsquared\n",
    "                           \n",
    "    # significant (<0.05): cpct, fpct, fspoints, liens,  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[['const', 'cpct', 'fpct', 'fspoints', 'liens', 'crating_composite', 'd_neg', 'fscore','hicdtmax', 'npayexpp', 'orating_composite', 'payexp_n', 'paynorm', 'avg_pydx_12', 'avg_pydx_24', 'sub_ind', 'suits', 'totdoll', 'uccfilng']]\n",
    "print(list(x))     # manually rearrange the order of the valuables so that significant variables are in the front\n",
    "                   # and list out the x variable candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_variables(y,x,show=False):                            # test x variable one at a time, using the adj.rsquared     \n",
    "    col = x          \n",
    "    clmn = list(col)\n",
    "    xlist = [clmn[0],clmn[1]]\n",
    "    for a in clmn[2:3]:\n",
    "        model = sm.OLS(y, col[xlist]).fit()\n",
    "        adj_r2 = model.rsquared_adj\n",
    "        xlist.append(a)\n",
    "        new_model = sm.OLS(y, col[xlist]).fit()\n",
    "        new_adj_r2 = new_model.rsquared_adj\n",
    "        print(\"old_adj_r2: \", adj_r2)\n",
    "        print(\"new_adj_r2: \", new_adj_r2)\n",
    "        print(\"pvalues: \")\n",
    "        print(new_model.pvalues)\n",
    "        print('\\n')\n",
    "        if new_adj_r2 >= adj_r2:\n",
    "            print(\"KEEP variable: \", clmn[2])\n",
    "        else: \n",
    "            print(\"DROP variable: \", clmn[2])  \n",
    "        if show:\n",
    "            print('\\n')\n",
    "            print(model.summary()) \n",
    "            print(new_model.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_variables(y,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logit_model=sm.Logit(y,x)\n",
    "result=logit_model.fit()\n",
    "print(result.summary())             #none"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.exp(result.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[['const', 'cpct', 'fspoints', 'liens', 'crating_composite', 'd_neg', 'fscore','hicdtmax', 'npayexpp', 'orating_composite', 'payexp_n', 'paynorm', 'avg_pydx_12', 'avg_pydx_24', 'sub_ind', 'suits', 'totdoll', 'uccfilng']]\n",
    "test_variables(y,x)    # manually drop 'fpct'\n",
    "                       # and do the adjusted rsquared test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[['const', 'cpct', 'liens', 'crating_composite', 'd_neg', 'fscore','hicdtmax', 'npayexpp', 'orating_composite', 'payexp_n', 'paynorm', 'avg_pydx_12', 'avg_pydx_24', 'sub_ind', 'suits', 'totdoll', 'uccfilng']]\n",
    "test_variables(y,x)     # manually drop 'fspoints'\n",
    "                        # and do the adjusted rsquared test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_variables(y,x,show=False):                            # after keeping 'liens', modify the function    \n",
    "    col = x          \n",
    "    clmn = list(col)\n",
    "    xlist = [clmn[0],clmn[1],clmn[2]]\n",
    "    for a in clmn[3:4]:\n",
    "        model = sm.OLS(y, col[xlist]).fit()\n",
    "        adj_r2 = model.rsquared_adj\n",
    "        xlist.append(a)\n",
    "        new_model = sm.OLS(y, col[xlist]).fit()\n",
    "        new_adj_r2 = new_model.rsquared_adj\n",
    "        print(\"old_adj_r2: \", adj_r2)\n",
    "        print(\"new_adj_r2: \", new_adj_r2)\n",
    "        print(\"pvalues: \")\n",
    "        print(new_model.pvalues)\n",
    "        print('\\n')\n",
    "        if new_adj_r2 >= adj_r2:\n",
    "            print(\"KEEP variable: \", clmn[3])\n",
    "        else: \n",
    "            print(\"DROP variable: \", clmn[3])  \n",
    "        if show:\n",
    "            print('\\n')\n",
    "            print(model.summary()) \n",
    "            print(new_model.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_variables(y,x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[['const', 'cpct', 'liens', 'd_neg', 'fscore','hicdtmax', 'npayexpp', 'orating_composite', 'payexp_n', 'paynorm', 'avg_pydx_12', 'avg_pydx_24', 'sub_ind', 'suits', 'totdoll', 'uccfilng']]\n",
    "test_variables(y,x)     # manually drop 'crating_composite'\n",
    "                        # and do the adjusted rsquared test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[['const', 'cpct', 'liens', 'fscore','hicdtmax', 'npayexpp', 'orating_composite', 'payexp_n', 'paynorm', 'avg_pydx_12', 'avg_pydx_24', 'sub_ind', 'suits', 'totdoll', 'uccfilng']]\n",
    "test_variables(y,x)     # manually drop 'd_neg'\n",
    "                        # and do the adjusted rsquared test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[['const', 'cpct', 'liens', 'hicdtmax', 'npayexpp', 'orating_composite', 'payexp_n', 'paynorm', 'avg_pydx_12', 'avg_pydx_24', 'sub_ind', 'suits', 'totdoll', 'uccfilng']]\n",
    "test_variables(y,x)     # manually drop 'fscore'\n",
    "                        # and do the adjusted rsquared test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the pvalue for hicdtmax is above 0.05, drop variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = x[['const', 'cpct', 'liens', 'npayexpp', 'orating_composite', 'payexp_n', 'paynorm', 'avg_pydx_12', 'avg_pydx_24', 'sub_ind', 'suits', 'totdoll', 'uccfilng']]\n",
    "test_variables(y,x)     # manually drop 'hicdtmax'\n",
    "                        # and do the adjusted rsquared test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[['const', 'cpct', 'liens', 'orating_composite', 'payexp_n', 'paynorm', 'avg_pydx_12', 'avg_pydx_24', 'sub_ind', 'suits', 'totdoll', 'uccfilng']]\n",
    "test_variables(y,x)     # manually drop 'npayexpp'\n",
    "                        # and do the adjusted rsquared test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[['const', 'cpct', 'liens', 'payexp_n', 'paynorm', 'avg_pydx_12', 'avg_pydx_24', 'sub_ind', 'suits', 'totdoll', 'uccfilng']]\n",
    "test_variables(y,x)     # manually drop 'orating_composite'\n",
    "                        # and do the adjusted rsquared test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[['const', 'cpct', 'liens', 'paynorm', 'avg_pydx_12', 'avg_pydx_24', 'sub_ind', 'suits', 'totdoll', 'uccfilng']]\n",
    "test_variables(y,x)     # manually drop 'payexp_n'\n",
    "                        # and do the adjusted rsquared test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[['const', 'cpct', 'liens', 'avg_pydx_12', 'avg_pydx_24', 'sub_ind', 'suits', 'totdoll', 'uccfilng']]\n",
    "test_variables(y,x)     # manually drop 'paynorm'\n",
    "                        # and do the adjusted rsquared test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the pvalue for hicdtmax is above 0.05, drop variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[['const', 'cpct', 'liens','avg_pydx_24', 'sub_ind', 'suits', 'totdoll', 'uccfilng']]\n",
    "test_variables(y,x)     # manually drop 'avg_pydx_12'\n",
    "                        # and do the adjusted rsquared test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the pvalue for hicdtmax is above 0.05, drop variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[['const', 'cpct', 'liens', 'sub_ind', 'suits', 'totdoll', 'uccfilng']]\n",
    "test_variables(y,x)     # manually drop 'avg_pydx_24'\n",
    "                        # and do the adjusted rsquared test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[['const', 'cpct', 'liens', 'suits', 'totdoll', 'uccfilng']]\n",
    "test_variables(y,x)     # manually drop 'sub_ind'\n",
    "                        # and do the adjusted rsquared test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[['const', 'cpct', 'liens', 'totdoll', 'uccfilng']]\n",
    "test_variables(y,x)     # manually drop 'suits'\n",
    "                        # and do the adjusted rsquared test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[['const', 'cpct', 'liens', 'uccfilng']]\n",
    "test_variables(y,x)     # manually drop 'totdoll'\n",
    "                        # and do the adjusted rsquared test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[['const', 'cpct', 'liens']]      # manually drop 'uccfilng'\n",
    "                                      # and show the regression result\n",
    "model = sm.OLS(y, x).fit()              \n",
    "print_model = model.summary()\n",
    "print(print_model)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
